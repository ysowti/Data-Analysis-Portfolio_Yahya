{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8pkecuheAs8"
   },
   "source": [
    "<img src=\"../Pics/MLSb-T.png\" width=\"160\">\n",
    "<br><br>\n",
    "<center><u><H1>Emotion Recognition with LSTM and Attention Mechanism</H1></u></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In This project I use Attention mechanism and LSTM to perform sentiment analysis to detect emotions in a text. The idea is to present a text that will be classified as specific type of emotion based on different classes that represent different types of emotions. In this approach using attention mechanism I try to identify main words in each text that can be associated with a specific type of emotion. This notebook is run in Google Colab with hardware accelerator chosen to be GPU. The data I work with in this project is 'emotion.csv' that contains text in each row and an emotion associated with that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3075,
     "status": "ok",
     "timestamp": 1575475874854,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "inUCvYZAeAs_",
    "outputId": "1c725757-9431-49ac-cc68-be596bebf6d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yr-DlsrGeAtD"
   },
   "outputs": [],
   "source": [
    "from keras import Model, Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, CuDNNLSTM, Dropout, TimeDistributed, Reshape, Activation, Dot\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "from IPython.core.display import display, HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step I load the data from csv file into a dataframe and get histogram of different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22619,
     "status": "ok",
     "timestamp": 1575475906838,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "l4IMDRCFes3-",
    "outputId": "aacbe2f5-33f5-4b12-d227-0ea97a89814e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1801,
     "status": "ok",
     "timestamp": 1575475912362,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "ugUq2iBZeAtF",
    "outputId": "a19ac0a2-fb4d-43db-845a-66e10bd3e99f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27383</td>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110083</td>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140764</td>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100071</td>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2837</td>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18231</td>\n",
       "      <td>i find myself frustrated with christians becau...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10714</td>\n",
       "      <td>i am one of those people who feels like going ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35177</td>\n",
       "      <td>i feel especially pleased about this as this h...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>122177</td>\n",
       "      <td>i was struggling with these awful feelings and...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26723</td>\n",
       "      <td>i feel so enraged but helpless at the same time</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text emotions\n",
       "0       27383  i feel awful about it too because it s my job ...  sadness\n",
       "1      110083                              im alone i feel awful  sadness\n",
       "2      140764  ive probably mentioned this before but i reall...      joy\n",
       "3      100071           i was feeling a little low few days back  sadness\n",
       "4        2837  i beleive that i am much more sensitive to oth...     love\n",
       "5       18231  i find myself frustrated with christians becau...     love\n",
       "6       10714  i am one of those people who feels like going ...      joy\n",
       "7       35177  i feel especially pleased about this as this h...      joy\n",
       "8      122177  i was struggling with these awful feelings and...      joy\n",
       "9       26723    i feel so enraged but helpless at the same time    anger"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/content/drive/My Drive/Colab_Notebooks/data/emotion.data\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1575475915994,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "Nh0iWfPqeAtI",
    "outputId": "472a5203-6de3-489c-ce2a-8e4c082dc324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7043acdc88>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEpIREREVUIiIiKqEhIREVH1/wGfA/dLdXaziQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I perform text tokenization by converting each text into tokens and storing it into a list. Then I use tokenizer to convert these tokens to numbers and create word to index and index to word dictionaries based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0P4-dkgceAtK"
   },
   "outputs": [],
   "source": [
    "text_tokens = [text.split(\" \") for text in df[\"text\"].values.tolist()]\n",
    "text = df[\"text\"].values.tolist()\n",
    "labels = df[\"emotions\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1575475925919,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "eUfNSJf3eAtM",
    "outputId": "58ea85ba-0103-47ed-bef9-253353d20956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70187,
     "status": "ok",
     "timestamp": 1573748006284,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "gC4slQMZeAtP",
    "outputId": "ada3bba2-ab7f-4710-f5ac-e3034fc732ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'awful', 'about', 'it', 'too', 'because', 'it', 's', 'my', 'job', 'to', 'get', 'him', 'in', 'a', 'position', 'to', 'succeed', 'and', 'it', 'just', 'didn', 't', 'happen', 'here']\n"
     ]
    }
   ],
   "source": [
    "print(text_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1575475929962,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "OX686jZ4eAtR",
    "outputId": "27069328-0fb3-4c02-eab6-0f81f19e1855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jFzrqxZ3eAtT"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yXJbqH-CeAtV"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K4Q5RGkMeAtX"
   },
   "outputs": [],
   "source": [
    "word2id = tokenizer.word_index\n",
    "id2word = dict([(value, key) for (key, value) in word2id.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1575476140018,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "r63slux7eAtZ",
    "outputId": "1c85f1a6-9b14-46a4-a59a-ed6e3f0a477e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'feel': 2, 'and': 3, 'to': 4, 'the': 5, 'a': 6, 'feeling': 7, 'that': 8, 'of': 9, 'my': 10, 'in': 11, 'it': 12, 'like': 13, 'so': 14, 'for': 15, 'im': 16, 'have': 17, 'me': 18, 'but': 19, 'was': 20, 'is': 21, 'this': 22, 'am': 23, 'with': 24, 'not': 25, 'be': 26, 'about': 27, 'as': 28, 'on': 29, 'you': 30, 'just': 31, 'when': 32, 'at': 33, 'or': 34, 'all': 35, 'because': 36, 'more': 37, 'do': 38, 'can': 39, 'really': 40, 'up': 41, 't': 42, 'know': 43, 'by': 44, 'are': 45, 'very': 46, 'been': 47, 'out': 48, 'myself': 49, 'what': 50, 'if': 51, 'time': 52, 'how': 53, 'get': 54, 'little': 55, 'will': 56, 'had': 57, 'now': 58, 'from': 59, 'being': 60, 'people': 61, 'they': 62, 'would': 63, 'he': 64, 'her': 65, 'want': 66, 'one': 67, 'think': 68, 'them': 69, 'still': 70, 'some': 71, 'ive': 72, 'even': 73, 'who': 74, 'much': 75, 'an': 76, 'we': 77, 'life': 78, 'him': 79, 'its': 80, 'there': 81, 'something': 82, 's': 83, 'things': 84, 'way': 85, 'bit': 86, 'm': 87, 'make': 88, 'love': 89, 'dont': 90, 'going': 91, 'could': 92, 'than': 93, 'too': 94, 'no': 95, 'day': 96, 'she': 97, 'go': 98, 'don': 99, 'has': 100}\n"
     ]
    }
   ],
   "source": [
    "print(dict(list(word2id.items())[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82957,
     "status": "ok",
     "timestamp": 1573748019152,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "TftwDBGGeAtb",
    "outputId": "b8a0613c-f159-476e-f61b-0ac4b8eea2a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75303"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2id) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZ4hM8-6eAtg"
   },
   "source": [
    "## Generating data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to generate data but before that I specify some hyperparameters including the length of embedding dimension that denotes the size of the vector each token will be represented by and max_len that indicats the maximum length in the sequence. Then I convert tokens of each tokenized sequence to numbers based on word2id dictionary and pad each sequence with 0's to make sure that we get sequences of length max_len. Finally, labels are transformed to numbers and target array y is formed by converting these numerical labels to categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CVkYQoBGeAth"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "max_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 83207,
     "status": "ok",
     "timestamp": 1573748019425,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "Ga-xwZ9OeAti",
    "outputId": "29e09b5e-f18b-4525-bcb5-04c2caf771a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 472, 27, 12, 94, 36, 12, 83, 10, 329, 4, 54, 79, 11, 6, 1159, 4, 2967, 3, 12, 31, 260, 42, 538, 134]\n"
     ]
    }
   ],
   "source": [
    "X = [[word2id[word] for word in sent] for sent in text_tokens]\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HnlWH1VAeAtk"
   },
   "outputs": [],
   "source": [
    "pad = 'post'\n",
    "X_pad = pad_sequences(X, maxlen=max_len, padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86264,
     "status": "ok",
     "timestamp": 1573748022498,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "CIWIh627eAtm",
    "outputId": "ddf8bd20-6090-4962-94ce-37717dbd9fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2  472   27   12   94   36   12   83   10  329    4   54   79\n",
      "   11    6 1159    4 2967    3   12   31  260   42  538  134    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86253,
     "status": "ok",
     "timestamp": 1573748022499,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "Sc_cyt-feAto",
    "outputId": "9126e9bf-bc66-43b4-f2c9-fa6efa9e588e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'sadness', 1: 'surprise', 2: 'love', 3: 'fear', 4: 'joy', 5: 'anger'}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {l: i for i, l in enumerate(set(labels))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "j0ANs_a_eAtq"
   },
   "outputs": [],
   "source": [
    "y = [label2id[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "13DgCtugeAts"
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=len(label2id), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86237,
     "status": "ok",
     "timestamp": 1573748022501,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "zULb5g0CeAtv",
    "outputId": "c9a33628-40a6-442d-ae9c-70de5ee1a0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (shape): (416809, 150)\n",
      "y (shape): (416809, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"X (shape): {}\".format(X_pad.shape))\n",
    "print(\"y (shape): {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9_KYunzeAty"
   },
   "source": [
    "## Creating the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, model is created based on functional approach in keras. In the first layer input of shape of max_len is created, then next layer is embedding layer that maps each word to its embedding vector that is then followed by a dropout layer with dropout rate of 0.2. The next layer is LSTM layer with output size of embedding_dim wrapped in a Bidirectional function that performs mapping of sequences in both forward and reverse directions. The main reason of using this wrapper function is getting a better accuracy. We need to return all hidden states to perform attention mechanism. This layer is followed by another dropout layer with the same rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86220,
     "status": "ok",
     "timestamp": 1573748022502,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "YiZpZsrMeAty",
    "outputId": "21c6a8ef-6325-4a3b-e10e-a97df16f9170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_input = Input(shape=(max_len,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86210,
     "status": "ok",
     "timestamp": 1573748022502,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "3cLgh6IVeAt0",
    "outputId": "f454c2bf-81d0-429e-90f0-fa5224861823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedded = Embedding(vocab_size,\n",
    "                     embedding_dim,\n",
    "                     input_length=max_len)(seq_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86201,
     "status": "ok",
     "timestamp": 1573748022503,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "NivLD9B4eAt1",
    "outputId": "4caa8847-7f98-44f7-b965-91ce9096e34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "embedded = Dropout(0.2)(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dhuMB9i3eAt3"
   },
   "outputs": [],
   "source": [
    "lstm = Bidirectional(CuDNNLSTM(embedding_dim, return_sequences=True))(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zO4J7GyfeAt5"
   },
   "outputs": [],
   "source": [
    "lstm = Dropout(0.2)(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIBiaZEeeAt7"
   },
   "source": [
    "### Attention mechanism:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to add attention mechanism to our layers. In order to do that, I first add time distributed function to output one time step in the sequence for each timestep in the input as a one to one relationship. The next layer reshapes output of previouse layer in vectors of size max_len that contains all timesteps. Then these vectors are fed into a softmax layer to generate attention vector that contains weights that sum up to one. Now we have weigths given by attention vector and can perform dot product between these weights and output of the last lstm layer that contains information of all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AIs3L1_veAt7"
   },
   "outputs": [],
   "source": [
    "att_vector = TimeDistributed(Dense(1))(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "D2H-tU4MeAt9"
   },
   "outputs": [],
   "source": [
    "att_vector = Reshape((max_len,))(att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "13IN1UqheAt-"
   },
   "outputs": [],
   "source": [
    "att_vector = Activation('softmax', name='attention_vec')(att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "S9KvC-HfeAuB"
   },
   "outputs": [],
   "source": [
    "att_output = Dot(axes=1)([lstm, att_vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4asQeKEfeAuD"
   },
   "source": [
    "### Final layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of attention layer is fed to a dense layer with output size of embedding_dim and activation function of relu. The final layer is a dense layer with output size of number of labels and activation of softmax to construct probabilities per label and classify each text in a specific label. Now we have the input and output based on which we can create the model with the given summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gik-zcACeAuD"
   },
   "outputs": [],
   "source": [
    "fc = Dense(embedding_dim, activation='relu')(att_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tRkv-6LGeAuF"
   },
   "outputs": [],
   "source": [
    "output = Dense(len(label2id), activation='softmax')(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KZ_mg3IbeAuG"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[seq_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88619,
     "status": "ok",
     "timestamp": 1573748024964,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "tTDQg_1geAuI",
    "outputId": "1136a6d6-de8c-4c47-e34f-c5ebf4d64feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 100)     7530300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 150, 100)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 150, 200)     161600      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 150, 200)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 150, 1)       201         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 150)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 150)          0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            606         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,712,807\n",
      "Trainable params: 7,712,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj7KbvQGeAuL"
   },
   "source": [
    "## Compiling the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is compiled with categorical crossentropy as loss, accuracy as metric using Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88610,
     "status": "ok",
     "timestamp": 1573748024965,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "Rp6PvU5UeAuL",
    "outputId": "ffabc0cf-42e7-4ace-f7ba-d01df82541ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzJvXtQ0eAuP"
   },
   "source": [
    "## Training the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for the training. I use fit method to train the model with input of fixed length X_pad, output y, number of epochs 2 and batch size of 64. I am also splitting data and randomly sampling 20% of data and using it for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 806536,
     "status": "ok",
     "timestamp": 1573748742901,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "LJptrhSKeAuR",
    "outputId": "062eaf64-6340-4040-b225-5c1986f43d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 333447 samples, validate on 83362 samples\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 362s - loss: 0.2022 - acc: 0.9026 - val_loss: 0.0983 - val_acc: 0.9399\n",
      "Epoch 2/2\n",
      " - 353s - loss: 0.0925 - acc: 0.9414 - val_loss: 0.0887 - val_acc: 0.9415\n",
      "CPU times: user 7min 54s, sys: 2min 40s, total: 10min 35s\n",
      "Wall time: 11min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecbd0f2128>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_pad, y, epochs=2, batch_size=64, validation_split=0.2, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0XA7MjReAuT"
   },
   "source": [
    "## Loading the Attention Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to load this attention layer and use it for illustration to show how the attention works. The idea is to present a text and select the main word in that text using attention mechanism. For that reason, I construct the attention model using the input and labels from the main model as well as output of the retrieved attention layer. Here, I retrieve the contents of the attention layer that was named before and use it to construct this variable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "x2h1dIuFeAuT"
   },
   "outputs": [],
   "source": [
    "model_att = Model(inputs=model.input,\n",
    "                  outputs=[model.output, model.get_layer('attention_vec').output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x266ufAKeAuV"
   },
   "source": [
    "## Testing with a sample text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to randomly select a text from dataset, preprocess it by tokenizing and padding it and then feed the encoded text to attention model constructed in the previouse step. The output of prediction by attention model will be two variables one to store the the predicted probabilities for each label and one to store the attention vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1596,
     "status": "ok",
     "timestamp": 1573748851933,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "f7rAxluleAuV",
    "outputId": "c5b6e851-321a-42c4-be44-3687c28d0f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can count on her for anything and i feel so blessed to have her for my mother\n"
     ]
    }
   ],
   "source": [
    "sample_text = random.choice(df[\"text\"].values.tolist())\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IbyOjJgieAuX"
   },
   "outputs": [],
   "source": [
    "tokenized_sample = sample_text.split(\" \")\n",
    "encoded_samples = [[word2id[word] for word in tokenized_sample]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K5JXPCaKeAuZ"
   },
   "outputs": [],
   "source": [
    "encoded_samples = pad_sequences(encoded_samples, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ENcibrUAeAub"
   },
   "outputs": [],
   "source": [
    "label_probs, attentions = model_att.predict(encoded_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJ_wjz48eAue"
   },
   "source": [
    "### Probabilities for each class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step I retrieve the predicted probabilities for each class using attention model. As you can see 'love' is the predicted label for this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1573748873139,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "J2GdYvXgeAuf",
    "outputId": "4db38518-c057-4a83-ebee-0cbb722c971a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness': 2.467789e-05, 'surprise': 1.6052543e-05, 'love': 0.5507866, 'fear': 1.1408465e-05, 'joy': 0.44910848, 'anger': 5.277812e-05}\n"
     ]
    }
   ],
   "source": [
    "label_probs = {id2label[_id]: prob for (label, _id), prob in zip(label2id.items(),label_probs[0])}\n",
    "\n",
    "print(label_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpzki-fJeAui"
   },
   "source": [
    "### Attention vector in the text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention vector is a softmax fuction output that assigned different scores to each word in the text. Using these scores we can see what is most important word for the attention mechanism and use it for visualization in the next step. Here, we can see that 'blessed' and 'feel' are the most important words in the text with the highest scores in the attention vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1643,
     "status": "ok",
     "timestamp": 1573749896733,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "E8bWBfqUzZfY",
    "outputId": "4ebb9b4f-b21a-4dcc-f5a2-49c383481211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'can',\n",
       " 'count',\n",
       " 'on',\n",
       " 'her',\n",
       " 'for',\n",
       " 'anything',\n",
       " 'and',\n",
       " 'i',\n",
       " 'feel',\n",
       " 'so',\n",
       " 'blessed',\n",
       " 'to',\n",
       " 'have',\n",
       " 'her',\n",
       " 'for',\n",
       " 'my',\n",
       " 'mother']"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1573748880193,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "vuw2M9iOeAui",
    "outputId": "b97e0a33-ac94-494b-aa31-b1691bc52344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 0.00022276881, 'can': 1.3408643e-05, 'count': 2.8349523e-05, 'on': 3.2081876e-05, 'her': 0.0012502039, 'for': 0.0046075713, 'anything': 0.00016576148, 'and': 0.00025751226, 'feel': 0.01928262, 'so': 0.035183597, 'blessed': 0.92931646, 'to': 0.0029638929, 'have': 0.0027329172, 'my': 0.00093843124, 'mother': 0.002039255}\n"
     ]
    }
   ],
   "source": [
    "token_attention_dic = {}\n",
    "max_score = 0.0\n",
    "min_score = 0.0\n",
    "for token, attention_score in zip(tokenized_sample, attentions[0][-len(tokenized_sample):]):\n",
    "    token_attention_dic[token] = attention_score\n",
    "\n",
    "print(token_attention_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwjGDOL1eAum"
   },
   "source": [
    "## Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform the visualization of this attention mechansim and labels. To perform these visualizations I am going to work in HTML format. I use rgb function for the format of the color and transform these colors to hex format to work in HTML. The function attention_color creates colors for the attention vector that first calculates rgb color based on attention score, and then converts if to hex format and returns it in string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lueCZBhleAum"
   },
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_scEI8uqeAup"
   },
   "outputs": [],
   "source": [
    "def attention_color(attention_score):\n",
    "    c = 255 - int(attention_score * 255)\n",
    "    color = rgb_to_hex((c,255,c))\n",
    "    return str(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpgGXAGreAur"
   },
   "source": [
    "### Visualizing attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the idea is to visualize the input text and the key words for the attention mechanism marked in a specific color by coloring the background of each word depending on its weight in attention mechanism. Next, I use display function to pass that to the HTML function in order to bring it to HTML format. The result as you can see is the text with most important key work 'blessed' marked in green. This is the word attention mechanism is focusing to classify the text as a specific label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R-CRKnv2eAus"
   },
   "outputs": [],
   "source": [
    "html_text = \"<hr><p style='font-size: large'><b>Text:  </b>\"\n",
    "for word, att in token_attention_dic.items():\n",
    "    html_text += \"<span style='background-color:{};'>{} <span> \".format(attention_color(att), word)\n",
    "html_text += \"</p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2220,
     "status": "ok",
     "timestamp": 1573748904400,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "NhpeqkA1eAut",
    "outputId": "5dcf3ec8-c078-4166-dda3-49475afbe3d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:  </b><span style='background-color:#ffffff;'>i <span> <span style='background-color:#ffffff;'>can <span> <span style='background-color:#ffffff;'>count <span> <span style='background-color:#ffffff;'>on <span> <span style='background-color:#ffffff;'>her <span> <span style='background-color:#fefffe;'>for <span> <span style='background-color:#ffffff;'>anything <span> <span style='background-color:#ffffff;'>and <span> <span style='background-color:#fbfffb;'>feel <span> <span style='background-color:#f7fff7;'>so <span> <span style='background-color:#13ff13;'>blessed <span> <span style='background-color:#ffffff;'>to <span> <span style='background-color:#ffffff;'>have <span> <span style='background-color:#ffffff;'>my <span> <span style='background-color:#ffffff;'>mother <span> </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I visualize probabilities as output of softmax function for all classes showing each class in a different color. As you can see 'Love' and 'Joy' are classes with the highest probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2490,
     "status": "ok",
     "timestamp": 1573748913377,
     "user": {
      "displayName": "Yahya Sowti",
      "photoUrl": "",
      "userId": "13837999519936229295"
     },
     "user_tz": 480
    },
    "id": "k0d1wYBSeAuv",
    "outputId": "d38b1f76-4e6f-4158-d638-158e628c1a81"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADCCAYAAAAvvYsEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions = [label for label, _ in label_probs.items()]\n",
    "scores = [score for _, score in label_probs.items()]\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.bar(np.arange(len(emotions)), scores, align='center', alpha=0.5, color=['pink', 'red', 'orange', 'brown', 'cyan', \"purple\"])\n",
    "plt.xticks(np.arange(len(emotions)), emotions)\n",
    "plt.ylabel('Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Emotion recognition with LSTM and Attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
